#+TITLE: 59 Ways To Improve Python
#+STARTUP: logdone inlineimages
#+OPTIONS: toc:nil num:nil
#+TODO: TODO IN-PROGRESS | DONE(!)

** Pythonic Thinking

*** DONE 1. Know Which Version of Python You're Using
    CLOSED: [2019-05-28 Tue 10:35]

    #+begin_src sh
      python --version
      python3 --version
      which python
    #+end_src

    #+RESULTS:
    | Python                            | 3.6.2 |
    | Python                            | 3.6.2 |
    | /Users/------/.pyenv/shims/python |       |

*** DONE 2. Follow the PEP (Python Enhancement Proposal) 8 Style Guide
    CLOSED: [2019-05-28 Tue 10:35]

    #+begin_quote
    Don't do this manually, use a tool like =autopep8= and =pylint=.
    #+end_quote

**** Naming
    
     - Functions, variables, and attributes should be in =lowercase_underscore= format.
     - Protected instance attributes should be in =_leading_underscore= format.
     - Private instance attributes should be in =__double_leading_underscore= format.
     - Classes and exceptions should be in =CapitalizedWord= format.
     - Module-level constants should be in =ALL_CAPS= format.
     - Instance methods in classes should use =self= as the name of the first parameter (which refers to the object).
     - Class methods should use =cls= as the name of the first parameter (which refers to the class). 

**** Expressions and Statements
    
     - Use inline negation =(if a is not b)= instead of negation of positive expressions =(if not a is b)=
     - Don't check for empty values (like =[]= or =''=) by checking the length =(if len(somelist) == 0=. Use =if not somelist= and assume empty values implicitly evaluate to =False=.
     - The same thing goes for non-empty values (like =[1]= or ='hi'=). The statement =if somelist= is implicitly =True= for non-empty values.
     - Avoid single-line =if= statements, =for= and =while= loops, and =except= compound statements. Spread these over multiple lines for clarity.
     - Always put =import= statements at the top of a file.
     - Always use absolute names for modules when importing them, not names relative to the current module's own path. For example, to import the =foo= module from the =bar= package, you should do =from bar import foo=, not just =import foo=.
     - Imports should be in sections in the following order: standard library modules, third=party modules, your own modules. Each subsection should have imports in alphabetical order.

*** DONE 3. Know the Differences Between =bytes=, =str=, and =unicode=
    CLOSED: [2019-05-29 Wed 21:57]

    - State "DONE"       from "IN-PROGRESS" [2019-05-29 Wed 21:57]
    - State "IN-PROGRESS" from "TODO"       [2019-05-29 Wed 21:57]
    No need to worry about =unicode= in Python 3. 

    #+begin_src python
      def to_str(bytes_or_str) -> str:
          if isinstance(bytes_or_str, bytes):
              value = bytes_or_str.decode('utf-8')
          else:
              value = bytes_or_str
          return value # Instance of str
    #+end_src
  
    #+begin_src python 
      def to_bytes(bytes_or_str) -> bytes:
          if isinstance(bytes_or_str, str):
              value = bytes_or_str.encode('utf-8')
          else:
              value = bytes_or_str
          return value # Instance of bytes
    #+end_src
   
    - In Python 3, =bytes= contains a sequence of 8-bit values, =str= contains sequences of Unicode chars. =bytes= and =str= instances can't be used together with operators (like =>= or =+=).
    - In Python 2, =str= contains sequences of 8-bit values, =unicode= contains sequences of Unicode chars. =str= and =unicode= /can/ be used together with operators if the =str= only contains 7-bit ASCII chars.
    - Use helper functions to ensure that the inputs you operate on are the type of char sequence you expect.
    - *If you want to read or write binary data to/from a file, always open the file using a binary mode (like ='rb'= or ='wb'=).

*** DONE 4. Write Helper Functions Instead of Complex Expressions
    CLOSED: [2019-05-29 Wed 22:07]

    - State "DONE"       from "IN-PROGRESS" [2019-05-29 Wed 22:07]
    - State "IN-PROGRESS" from "TODO"       [2019-05-29 Wed 22:07]
    Amen.

    #+begin_src python
      red = int(some_dict.get('red'), [''])[0] or 0) # bad

      # --------------------------

      red = some_dict.get('red', [''])
      red = int(red[0]) if red[0] else 0  # better, but still bad

      # --------------------------

      red = some_dict.get('red', [''])  # better, but verbose
      if red[0]:
          red = int(red[0])
      else:
          red = 0

      # --------------------------

      def get_first_int(some_dict, key, default=0):
          found = values.get(key, [''])
          if found[0]:
              found = int(found[0])
          else:
              found = default
          return found

      red = get_first_int(some_dict, 'red', 0)  # best.
    #+end_src

*** DONE 5. Know how to Slice Sequences
    CLOSED: [2019-05-29 Wed 22:44]

    - State "DONE"       from "IN-PROGRESS" [2019-05-29 Wed 22:44]
    - State "IN-PROGRESS" from "TODO"       [2019-05-29 Wed 22:44]
    #+begin_src python :session example
      a = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
      print('First Four: ', a[:4])
      print('Last Four: ', a[-4:])
      print('Middle Two: ', a[3:-3])

      # Leave out the zero index, because it's visual noise
      assert a[:5] == a[0:5]

      # Leave out the final index, because it's redundant
      assert a[5:] == a[5:len(a)]

      # Prefer clarity
      # a[start(inclusive):end(exclusive)]
      a[:]         # ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
      a[:5]        # ['a', 'b', 'c', 'd', 'e']
      a[:-1]       # ['a', 'b', 'c', 'd', 'e', 'f', 'g']
      a[4:]        #                     ['e', 'f', 'g', 'h']
      a[-3:]       #                          ['f', 'g', 'h']
      a[2:5]       #           ['c', 'd', 'e']
      a[2:-1]      #           ['c', 'd', 'e', 'f', 'g']
      a[-3:-1]     #                          ['f', 'g']
    #+end_src

    #+RESULTS:
    | f | g |

    Negative numbers =n= for the slice implies =len(a)-n=. Therefore

    #+begin_src python
      a = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
      assert a[-3:-1] == a[len(a)-3:len(a)-1] # == a[5:7]
    #+end_src

    Create new lists from slices. Splice lists into lists.

    #+begin_src python
      a = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']

      b = [4:]             # ['e', 'f', 'g', 'h']  NEW list
      b[1] = 99            # ['e', 99, 'g', 'h']
      print(a)             # ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']

      # Inject lists into lists

      a[2:7] = [1, 2, 3]   # ['a', 'b', 1, 2, 3, 'h']
    #+end_src

    - Don't be verbose -> =a[:5]= over =a[0:5]=
    - Slices won't give an IndexError if you slice out of range
    - Slices return a new list
    - Assigning to a =list= slice will replace that range in the original sequence with what's referenced even if their lengths differ.

*** DONE 6. Avoid Using =start=, =end=, and =stride= in a Single Slice
    CLOSED: [2019-05-30 Thu 22:40]

    - State "DONE"       from "IN-PROGRESS" [2019-05-30 Thu 22:40]
    - State "IN-PROGRESS" from "TODO"       [2019-05-30 Thu 22:40]
    What is =stride= used for? Taking every /nth/ item when slicing a sequence.

    =somelist[start:end:stride]=
   
    #+begin_src python :session example :exports both
      a = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
      evens = a[::2]              # ['a', 'c', 'e', 'g']
      odds = a[1::2]              # ['b', 'd', 'f', 'h']
      undesireable = a[1::-1]     # ['b', 'a'] 

      undesireable
    #+end_src

    #+RESULTS:
    | b | a |

    *Takeaways*
   
    - Specify =start=, =end=, and =stride= in a slice can be confusing.
    - Prefer using /positive/ =stride= values in slices without =start= or =end= indexes.
    - Avoid negative =stride= values.
    - Avoid using =start=, =end=, and =stride= together in a single slice. If you need both operations, use two assignments.

*** DONE 7. Use List Comprehensions Instead of =map= and =filter=
    CLOSED: [2019-05-30 Thu 22:54]

    - State "DONE"       from "IN-PROGRESS" [2019-05-30 Thu 22:54]
    - State "IN-PROGRESS" from "TODO"       [2019-05-30 Thu 22:54]
    /List Comprehensions/ are expressions that derive one list from another.
   
    #+begin_src python :session output drawer
      a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
      squares = [x**2 for x in a]
      squares
    #+end_src

    #+RESULTS:
    | 1 | 4 | 9 | 16 | 25 | 36 | 49 | 64 | 81 | 100 |


    Using the =map= built-in, we can achive the same result.

    #+begin_src python :session output drawer
      a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
      squares = map(lambda x: x**2, a)
      squares
    #+end_src

    #+RESULTS:
    | 1 | 4 | 9 | 16 | 25 | 36 | 49 | 64 | 81 | 100 |

    Filtering a /list comprehension/ is more concise than =map=/=filter=.

    #+begin_src python :session drawer
      a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
      lc_even_squares = [x**2 for x in a if x % 2 == 0] # Concise!
      mf_even_squares = map(lambda x: x**2, filter(lambda x: x % 2 == 0, a)) # VERBOSE
    #+end_src

    *Takeaways*

    - List comprehensions are clearer than =map= and =filter= because no need for =lambda=.
    - List comprehensions allow you to skip items from the list. =map= can't without =filter= and =lambda=s
    - Dicts and =sets= also support comprehension expressions.

*** DONE 8. Avoid More Than Two Expressions in List Comprehensions
    CLOSED: [2019-05-31 Fri 22:33]
    - State "DONE"       from "IN-PROGRESS" [2019-05-31 Fri 22:33]
    - State "IN-PROGRESS" from "TODO"       [2019-05-31 Fri 22:28]
    :LOGBOOK:
    CLOCK: [2019-05-31 Fri 22:26]--[2019-05-31 Fri 22:33] =>  0:07
    :END:

    Using two list comprehensions to flatten a matrix.

    #+begin_src python :session 
      matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
      flat = [x for row in matrix for x in row]
      flat
    #+end_src

    #+RESULTS:
    | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |

    This is readable and simple, but any more than two, and it starts to get messy.

    *Takeaways*
   
    While list comprehensions support multiple levels of loops and multiple conditions per loop level, any more than two should are difficult to read and be avoided. 

*** DONE 9. Consider Generator Expressions for Large Comprehensions
    CLOSED: [2019-05-31 Fri 22:56]
    - State "DONE"       from "IN-PROGRESS" [2019-05-31 Fri 22:56]
    :LOGBOOK:
    CLOCK: [2019-05-31 Fri 22:34]--[2019-05-31 Fri 22:56] =>  0:22
    :END:

    List comprehensions create a new list based off of the expressions.
    While this is good for small lists, it could end up consuming significant amounts of memory for large lists.

    #+begin_src python :session
      val = [len(x) for x in open('/tmp/small_file.txt')]
      print(val) # not bad for small files, but horrible for large files.
    #+end_src
   
    Prefer generators, which return an iterator instead of a new list. 
   
    #+begin_src python :session :results output
      iter = (len(x) for x in ['hello', 'how', 'do', 'you', 'do'])
      print(next(iter))   # len('hello')
      print(next(iter))   # len('how')
      print(next(iter))   # len('do')
    #+end_src

    #+RESULTS:
    : 5
    : 3
    : 2

    Compose Generators
   
    #+begin_src python :session :results output
      iter = (len(x) for x in ['hello', 'how', 'do', 'you', 'do'])
      roots = ((x, x**0.5) for x in iter)
      print(next(roots)) # next(roots) also advances iter
      print(next(roots))
      print(next(roots))
    #+end_src

    #+RESULTS:
    : (5, 2.23606797749979)
    : (3, 1.7320508075688772)
    : (2, 1.4142135623730951)

    *Takeaways*
   
    - Memory is a limitation with list comprehensions.
    - Generator expressions produce outputs one at a time, which avoids memory issues.
    - Generators expressions can be composed by passing an interator from a generator into the =for= of another.
    - Generator expressions are /fast/ when chained together.

*** DONE 10. Prefer =enumerate= over =range=
    CLOSED: [2019-05-31 Fri 23:22]
    - State "DONE"       from "IN-PROGRESS" [2019-05-31 Fri 23:22]
    :LOGBOOK:
    CLOCK: [2019-05-31 Fri 23:08]--[2019-05-31 Fri 23:22] =>  0:14
    :END:

    Use =range= for loops that iterate over a set of integers.

    #+begin_src python :session 
      random_bits = 0
      for i in range(64):
          if randint(0, 1):
              random_bits |= 1 << i
    #+end_src

    For data structures you need to iterate over, loop directly over the sequence.

    #+begin_src python :session :results output :exports both
      people = ['george', 'joe', 'harry', 'ivy']
      for person in people:
          print('%s is a person' % person)
    #+end_src

    #+RESULTS:
    : george is a person
    : joe is a person
    : harry is a person
    : ivy is a person

    Prefer =enumerate= over =range= when you need the index along with the data.
   
    #+begin_src python :session :results output :exports both
      people = ['george', 'joe', 'harry', 'ivy']
      for i in range(len(people)):
          print('%d: %s' % (i + 1, people[i])) # Pretty horrible

      for i, person in enumerate(people):
          print('%d: %s' % (i + 1, person)) # Pretty nice

      for i, person in enumerate(people, 1): # Start i at 1
          print('%d: %s' % (i, person)) # Pretty nice without arithmetic
    #+end_src

    #+RESULTS:
    #+begin_example
    1: george
    2: joe
    3: harry
    4: ivy
    1: george
    2: joe
    3: harry
    4: ivy
    1: george
    2: joe
    3: harry
    4: ivy
    #+end_example

    *Takeaways*

    - =enumerate= provides concise syntax for looping over an iterator and getting the index of each item from the iterator as you go.
    - Prefer =enumerate= over =range= and avoid indexing into a sequence.
    - =enumerate(iterable, {start_count})= supply a second param to =enumerate= to specify a starting count.

*** DONE 11. Use =zip= to Process Iterators in Parallel
    CLOSED: [2019-06-01 Sat 23:08]
    - State "DONE"       from "IN-PROGRESS" [2019-06-01 Sat 23:08]
    :LOGBOOK:
    CLOCK: [2019-06-01 Sat 22:54]--[2019-06-01 Sat 23:08] =>  0:14
    :END:

    Iterate over multiple lists in parallel efficiently (in Python 3)

    #+begin_src python :session 
      names = ['George', 'Ella', 'Mary']
      letters = [len(n) for n in names]

      # find the longest name, with range and messy code
      longest_name = None
      max_letters = 0

      for i in range(len(names)):
          count = letters[i]
          if count > max_letters:
              longest_name = names[i]
              max_letters = count

      print(longest_name)

      # slightly better using enumerate
      for i, name in enumerate(names):
          count = letters[i]
          if count > max_letters:
              longest_name = name # Fixed an index retrieval here
              max_letters = count

      # Just use zip
      for name, count in zip(names, letters):
          if count > max_letters:
              longest_name = name
              max_letters = count
    #+end_src

    *Takeaways*
   
    - =zip= can be used to iterate over multiple iterators in parallel
    - =zip= is a /lazy/ generator that produces tuples in Python 3. In Python 2 returns the full result as a list of tuples (Memory!)
    - =zip= truncates it output for lists of different lengths
    - Use =zip_longest= from =itertools= to iterate multiple iterators in parallel regardless of mismatched lengths

*** DONE 12. Avoid =else= Blocks After =for= and =while= Loops
    CLOSED: [2019-06-03 Mon 22:31]
    - State "DONE"       from "IN-PROGRESS" [2019-06-03 Mon 22:31]
    :LOGBOOK:
    CLOCK: [2019-06-03 Mon 22:21]--[2019-06-03 Mon 22:31] =>  0:10
    :END:

    While you could put =else= after =for= and =while=, why on earth would you do so?
   
    #+begin_src python :session :results output :export both
      for i in range(3):
          print('%d' % i)
      else:
          print('why?!!!') # this runs when the loop is finished
    #+end_src

    #+RESULTS:
    : 0
    : 1
    : 2
    : why?!!!

    What it really means is: If the loop is done, hit the =else=.

    #+begin_src python :session :results output :export both
      for i in range(3):
          print('%d' % i)
          if i == 1:
              break
      else:
          print('why?!!!') # Does not get hit because the loop did not "finish"
    #+end_src

    #+RESULTS:
    : 0
    : 1

    *Takeaways*
   
    - Python supports an =else= after =for= and =while= loops
    - =else= runs if the loop did not encounter a =break=
    - Avoid =else= after loops because it is not intuitive

*** DONE 13. Take Advantage of Each Block in =try/except/else/finally=
    CLOSED: [2019-06-04 Tue 23:05]
    - State "DONE"       from "IN-PROGRESS" [2019-06-04 Tue 23:05]
    :LOGBOOK:
    CLOCK: [2019-06-04 Tue 22:45]--[2019-06-04 Tue 23:05] =>  0:20
    :END:

    Finally Blocks: Primarily for cleanup code. Common Example:
   
    #+begin_src python :session
      handle = open('/tmp/something.txt')   # Exceptions here should bubble up and skip the finally below
      try:
          data = handle.read()
      finally:
          handle.close()  # Always runs after try:
    #+end_src

    Use =else= when you want to perform some operation if no exceptions occur

    #+begin_src python :session
      def load_json_key(data, key):
          try:
              result_dict = json.loads(data)    # May raise ValueError
          except ValueError as e:
              raise KeyError from e
          else:
              return result_dict[key]           # May raise KeyError (Bubble up)
    #+end_src

    Keeping everything in one compound statement:
   
    #+begin_src python :session
      UNDEFINED = object()

      def divide_json(path):
          handle = open(path, 'r+')   # May raise IOError (Bubble up)
          try:
              data = handle.read()    # May raise UnicodeDecodeError (Bubble up)
              op = json.loads(data)   # May raise ValueError (Bubble up)
              value = (
                  op['numerator'] /
                  op['denominator'])  # May raise ZeroDivisionError
          except ZeroDivisionError as e:
              return UNDEFINED
          else:
              op['result'] = value
              result = json.dumps(op)
              handle.seek(0)
              handle.write(result)    # May raise IOError (Bubble up)
              return value
          finally:
              handle.close()          # Always runs
    #+end_src

    *Takeaways*

    - =try/finally= lets you run cleanup code regardless whether exceptions were raised in the =try= block
    - =else= helps minimizes the code in =try= blocks and visually distinguish the success case from the =try/except= blocks
    - An =else= block can be used to perform additional actions after a successful =try= block but before common cleanup in a =finally=

     
** Functions

*** DONE 14. Prefer Exceptions to Returning =None=
    CLOSED: [2019-06-05 Wed 22:18]
    - State "DONE"       from "IN-PROGRESS" [2019-06-05 Wed 22:18]
    :LOGBOOK:
    CLOCK: [2019-06-05 Wed 22:00]--[2019-06-05 Wed 22:18] =>  0:18
    :END:

    In some cases, returning =None= is error prone. 
   
    #+begin_src python :session :results output
      def divide(a, b):
          try:
              return a / b
          except ZeroDivisionError:
              return None

      # Consuming this way *could* work

      result = divide(x, y)
      if result is None:
          print('Invalid inputs')

      # Consuming this way is incorrect

      result = divide(0, 5)  # Evaluates to 0
      if not result:
          print('Invalid inputs') # WRONG!
    #+end_src

    One way to reduce the chance of errors

    #+begin_src python :session :results output
      def divide(a, b):
          try:
              return True, a / b
          except ZeroDivisionError:
              return False, None

      # Consuming

      success, result = divide(x, y)
      if not success:
          print('Invalid Inputs')

      # But, it allows consumers to skip the success portion like:

      _, result = divide(x, y)
      if not result:
          print('Invalid Inputs')
    #+end_src


    The better way

    #+begin_src python :session :results output
      def divide(x, y):
          try:
              return x / y
          except ZeroDivisionError as e:
              raise ValueError('Invalid inputs') from e

      # Let the consumer handle the error

      try:
          result = divide(5, 2)
      except ValueError:
          print('Invalid Inputs')
      else:
          print('Result is %.1f' % result)
    #+end_src

    #+RESULTS:
    : Python 3.6.2 (default, Feb 25 2018, 09:55:00) 
    : [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)] on darwin
    : Type "help", "copyright", "credits" or "license" for more information.
    : Result is 2.5
   
    *Takeaways*

    - Functions that return =None= to indicate special meaning are error prone because =None= and other values (0, '') all evaluate to =False= in conditional expressions
    - Raise exceptions to indicate special situations instead of returning =None=. Expect the calling code to handle exceptions properly when they're documented

*** DONE 15. Know How Closures Interact with Variable Scope
    CLOSED: [2019-06-18 Tue 21:55]
    - State "DONE"       from "IN-PROGRESS" [2019-06-18 Tue 21:55]
    :LOGBOOK:
    CLOCK: [2019-06-18 Tue 21:31]--[2019-06-18 Tue 21:55] =>  0:24
    :END:
  
    Sorting a list by using a priority helper function (closure) works pretty well for simple inputs.
 
    #+begin_src python :session :results output :exports both
      def sort_priority(values, group):
          def helper(x):
              if x in group:
                  return (0, x)
              return (1, x)
          values.sort(key=helper)


      numbers = [8, 3, 1, 2, 5, 4, 7, 6]
      group = {2, 3, 5, 7}
      sort_priority(numbers, group)
      print(numbers)
    #+end_src

   #+RESULTS:
   : [2, 3, 5, 7, 1, 4, 6, 8]
   : 
   : 

   Trying to keep track of whether an item was found in the group is a little different.

    #+begin_src python :session :results output :exports both
      def sort_priority(values, group):
          found = False           # Scope: 'sort_priority'
          def helper(x):
              if x in group:
                  found = True    # Scope: 'helper'
                  return (0, x)
              return (1, x)
          values.sort(key=helper)
          return found


      numbers = [8, 3, 1, 2, 5, 4, 7, 6]
      group = {2, 3, 5, 7}
      found = sort_priority(numbers, group)
      print(found)
      print(numbers)
    #+end_src

    #+RESULTS:
    : False
    : [2, 3, 5, 7, 1, 4, 6, 8]
    : 
    : 

   The `print(found)` value is incorrect because of scoping issues. Let's try to get it using `nonlocal`.

    #+begin_src python :session :results output :exports both
      def sort_priority(values, group):
          found = False           # Scope: 'sort_priority'
          def helper(x):
              nonlocal found      # Scope: 'sort_priority' or the next scope up
              if x in group:
                  found = True    
                  return (0, x)
              return (1, x)
          values.sort(key=helper)
          return found


      numbers = [8, 3, 1, 2, 5, 4, 7, 6]
      group = {2, 3, 5, 7}
      found = sort_priority(numbers, group)
      print(found)
      print(numbers)
    #+end_src

    #+RESULTS:
    : True
    : [2, 3, 5, 7, 1, 4, 6, 8]
    : 
    : 

    Here the value for `print(found)` is correct now, but using `nonlocal` for anything but simple functions is BAD.
   
    Another solution is to wrap the state in a helper class.
   
    #+begin_src python :session :results output :exports both
      class Sorter(object):
          def __init__(self, group):
              self.group = group
              self.found = False

          def __call__(self, x):
              if x in self.group:
                  self.found = True
                  return (0, x)
              return (1, x)

      group = {2, 3, 5, 7}
      sorter = Sorter(group)
      numbers = [8, 3, 1, 2, 5, 4, 7, 6]
      numbers.sort(key=sorter)
      print(sorter.found)
      print(numbers)
    #+end_src

    #+RESULTS:
    : True
    : [2, 3, 5, 7, 1, 4, 6, 8]
    : 
    : 

   
    *Takeaways*

    - Closure functions can refer to veriables from any of the scopes in which they were defined.
    - By default, closures can't affect enclosing scopes by assigning variables.
    - In Python 3, use the `nonlocal` statement to indicate when a closure can modify a variable in its enclosing scopes.
    - Avoid using `nonlocal` statements for anything beyond simple functions.


*** DONE 16. Consider Generators Instead of Returning Lists
    CLOSED: [2019-06-20 Thu 22:24]
    - State "DONE"       from "IN-PROGRESS" [2019-06-20 Thu 22:24]
    :LOGBOOK:
    CLOCK: [2019-06-20 Thu 21:58]--[2019-06-20 Thu 22:24] =>  0:26
    :END:
   
    Dense and noisy appending to a list. The list must be filled before returning it. For large inputs, there could be memory issues.

    #+begin_src python :session :results output :exports both
      def index_words(text):
          result = []
          if text:
              result.append(0)
          for index, letter in enumerate(text):
              if letter == ' ':
                  result.append(index + 1)
          return result


      result = index_words('Four score and seven years ago...')
      print(result[:3])
    #+end_src

    #+RESULTS:
    : [0, 5, 11]
    : 
    : 

    Using a generator we cut down some code and make it a little easier to read.

    #+begin_src python :session :results output :exports both
      def index_words_iter(text):
          if text:
              yield 0
          for index, letter in enumerate(text):
              if letter == ' ':
                  yield index + 1

      result = index_words('Four score and seven years ago...')
      print(result[:3])
    #+end_src

    #+RESULTS:
    : [0, 5, 11]
    : 
    : 

   
    Handle large inputs more efficiently.

    #+begin_src python :session :results output :exports both
      # The working memory of this function is the size of the list coming in.
      # It doesn't create a new list, avoiding adding more memory to the function.
      def index_file(handle):
          offset = 0
          for line in handle:
              if line:
                  yield offset
              for letter in line:
                  offset += 1
                  if letter == ' ':
                      yield offset


      it = index_file([
          'Four score and seven years ago...',
          'Four score and seven years ago...',
          'Four score and seven years ago...'
      ])

      print(it)
      print(list(it))
    #+end_src

    #+RESULTS:
    : <generator object index_file at 0x10fed5b48>
    : [0, 5, 11, 15, 21, 27, 33, 38, 44, 48, 54, 60, 66, 71, 77, 81, 87, 93]
    : 
    : 

    *Takeaways*

    - Using generators can be clearer than the alternative of returning lists of accumulated results.
    - The interator returned by a generator produces the set of values passed to =yield= expressions within the generator function's body.
    - Generators can produce a sequence of outputs for arbitrarily large inputs because their working memory doesn't include all inputs and outputs.

  
*** DONE 17. Be Defensive When Iterating Over Arguments
    CLOSED: [2019-06-21 Fri 11:23]
    - State "DONE"       from "IN-PROGRESS" [2019-06-21 Fri 11:23]
    :LOGBOOK:
    CLOCK: [2019-06-21 Fri 10:48]--[2019-06-21 Fri 11:22] =>  0:34
    CLOCK: [2019-06-21 Fri 10:09]--[2019-06-21 Fri 10:40] =>  0:31
    :END:

    This works good for small inputs

    #+begin_src python :session :results output :exports both
      def normalize(numbers):
          total = sum(numbers)
          result = []
          for value in numbers:
              percent = 100 * value / total
              result.append(percent)
          return result


      visits = [15, 35, 80]
      percentages = normalize(visits)
      print(percentages)
    #+end_src

    #+RESULTS:
    : [11.538461538461538, 26.923076923076923, 61.53846153846154]
    : 
    : 

    To scale it up, use a generator
  
    #+begin_src python :session :results output :exports both
      def normalize(numbers):
          print(numbers)                      # Generator
          total = sum(numbers)
          print(total)
          print(sum(numbers))                 # Depleted so it's 0
          result = []
          for value in numbers:               # Depleted so numbers = []
              percent = 100 * value / total
              result.append(percent)
          return result


      def read_visits(multi_numbers):
          for row in multi_numbers:
              yield int(row)


      iter = read_visits([15, 35, 80])
      percentages = normalize(iter)
      print(percentages)                      # Empty because the iterator has been consumed


      # Let's try again
      iter2 = read_visits([15, 35, 80])
      print(list(iter2))                      # consuming the iterator
      print(list(iter2))                      # empty because it's consumed
    #+end_src

    #+RESULTS:
    : <generator object read_visits at 0x10ff1b5c8>
    : 130
    : 0
    : []
    : [15, 35, 80]
    : []
    : 
    : 

    There's no way of telling whether a iterator has been exhausted, so let's defensively copy the list

    #+begin_src python :session :results output :exports both
      def normalize_copy(numbers):
          numbers_list = list(numbers)       # Copy the iterator
          total = sum(numbers_list)
          result = []
          for value in numbers_list:
              percent = 100 * value / total
              result.append(percent)
          return result

      def read_visits(multi_numbers):
          for row in multi_numbers:
              yield int(row)

      iter = read_visits([15, 35, 80])
      percentages = normalize_copy(iter)
      print(percentages)                     # Works as expected
    #+end_src

    #+RESULTS:
    : [11.538461538461538, 26.923076923076923, 61.53846153846154]
    : 
    : 

    But what if the =numbers= argument is large? We can pass a function in that gets the iterator each time we need it.

    #+begin_src python :session :results output :exports both
      def normalize_func(get_iter_func):
          total = sum(get_iter_func())
          result = []
          for value in get_iter_func():
              percent = 100 * value / total
              result.append(percent)
          return result

      def read_visits(multi_numbers):
          for row in multi_numbers:
              yield int(row)

      iter = read_visits([15, 35, 80])
      percentages = normalize_func(lambda: read_visits([15, 35, 80]))
      print(percentages)                     # Works as expected
    #+end_src

    #+RESULTS:
    : [11.538461538461538, 26.923076923076923, 61.53846153846154]
    : 
    : 


    This works, but it's pretty clumsy, how about using a class instead that implements the =__iter__= method.
   
    #+begin_src python :session :results output :exports both
      class ReadVisits(object):
          def __init__(self, data_path):
              self.data_path = data_path

          def __iter__(self):
              for row in self.data_path:
                  yield int(row)

      def normalize(numbers_iter_object):
          total = sum(numbers_iter_object)   # Calls ReadVisits.__iter__
          result = []
          for value in numbers_iter_object:  # Calls ReadVisits.__iter__
              percent = 100 * value / total
              result.append(percent)
          return result

      visits = ReadVisits([15, 35, 80])
      percentages = normalize(visits)
      print(percentages)                     # Works as expected
    #+end_src

    #+RESULTS:
    : [11.538461538461538, 26.923076923076923, 61.53846153846154]
    : 
    : 

    Cleaner, but let's be defensive.
   
    #+begin_src python :session :results output
      class ReadVisits(object):
          def __init__(self, data_path):
              self.data_path = data_path

          def __iter__(self):
              for row in self.data_path:
                  yield int(row)

      def normalize(numbers_iter_object):
          if iter(numbers_iter_object) is iter(numbers_iter_object):
              raise TypeError('numbers_iter_object must not be an iter')

          total = sum(numbers_iter_object)   # Calls ReadVisits.__iter__
          result = []
          for value in numbers_iter_object:  # Calls ReadVisits.__iter__
              percent = 100 * value / total
              result.append(percent)
          return result


      visits = [15, 35, 80]
      percentages = normalize(visits)
      print(percentages)                     # Works as expected

      visits = ReadVisits([15, 35, 80])
      percentages = normalize(visits)
      print(percentages)                     # Works as expected

      it = iter([15, 35, 80])
      percentages = normalize(it)            # Throws a TypeError
      print(percentages)                     
    #+end_src

    #+RESULTS:
    #+begin_example
    /var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-9RVJJt/python-6E95Id in <module>
         24 
         25 visits = [15, 35, 80]
    ---> 26 percentages = normalize(visits)
         27 print(percentages)                     # Works as expected
         28 

    /var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-9RVJJt/python-6E95Id in normalize(numbers_iter_object)
         10 
         11     print(numbers_iter_object)
    ---> 12     print(iter(numbers_iter_object))
         13 
         14     if iter(numbers_iter_object) is iter(numbers_iter_object):

    TypeError: 'generator' object is not callable


    #+end_example

    *Takeaways*

    - Beware of functions that iterate over input arguments multiple times. If they are iterators, you may see strange behavior and missing values.
    - Python's iterator protocol defines how containers and iterators iteract with the =iter= and =next= built-in functions, =for= loops, and related expressions.
    - You can define your own iterable container by implementing the =__iter__= method as a generator.
    - You can check if a value is an iterator if calling =iter= on it twice produces the same result, which can then be progressed with the =next= built-in function.

     
*** DONE 18. Reduce Visual Noise with Variable Positional Arguments
    CLOSED: [2019-06-24 Mon 10:16]
    - State "DONE"       from "IN-PROGRESS" [2019-06-24 Mon 10:16]
    :LOGBOOK:
    CLOCK: [2019-06-24 Mon 09:48]--[2019-06-24 Mon 10:16] =>  0:28
    :END:
   
    Let's start with an example.

    #+begin_src python :session :results output :exports both
      def log(message, values):
          if not values:
              print(message)
          else:
              values_str = ', '.join(str(x) for x in values)
              print('%s: %s' % (message, values_str))

      log('My numbers are', [1, 2])
      log('No values here', [])                               # always have to pass a list 
    #+end_src

    #+RESULTS:
    : My numbers are: 1, 2
    : No values here
    : 
    : 

    Here, you'd always have to consider passing a list for the =values= parameter which is cumbersome and noisy.

    Let's support an optional =values= parameter.
   
    #+begin_src python :session :results output :exports both
      def log(message, *values):         # that was easy
          if not values:
              print(message)
          else:
              values_str = ', '.join(str(x) for x in values)
              print('%s: %s' % (message, values_str))

      log('My numbers are', 1, 2)
      log('No values here')                        


      # * on the argument side unpacks a list
      nums = [1,2,3,5,6]
      log('Numbers?', *nums)
    #+end_src

    #+RESULTS:
    : My numbers are: 1, 2
    : No values here
    : Numbers?: 1, 2, 3, 5, 6
    : 
    : 

    There are cons to this approach. 

    1. Variable arguments are always turned into a tuple before they are passed to the function. 

    If the caller uses the =*= operator on a generator, it will be iterated until it is exhausted. 
    The resulting tuple will include every value from the generator, which could consume a lot of memory and crash.

    #+begin_src python :session :results output :exports both
      def my_generator():
          for i in range(10):
              yield i

      def my_func(*args):
          print(args)

      it = my_generator()
      my_func(*it)              # turned into a tuple and consumed entire iterator

    #+end_src

    #+RESULTS:
    : (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
    : 
    : 

    Functions that accept =*args= are best when you know the number of inputs will be reasonably small.
    Use when passing many literals or variable names together for readability and convenience to callers.
  
    2. You can't add new positional arguments to your function without migrating _every_ caller. BREAKING CHANGES.

    #+begin_src python :session :results output :exports both
      def log(sequence, message, *values):    # adding sequence
          if not values:
              print('%s: %s' % (sequence, message))
          else:
              values_str = ', '.join(str(x) for x in values)
              print('%s: %s: %s' % (sequence, message, values_str))

      log(1, 'Favs', 7, 8)
      log('Favs', 7, 8)               # Broken visually but not easy to find why
    #+end_src

    #+RESULTS:
    : 1: Favs: 7, 8
    : Favs: 7: 8
    : 
    : 

    *Takeaways*
   
    - Use =*args= in your function to accept a variable number of positional arguments.
    - Use =*= to unpack a sequence into a sequence of positional arguments.
    - Using =*args= with a generator may cause a crash due to memory.
    - Adding new positional parameters to functions that accept =*args= can introduce hard to find bugs.

     
*** DONE 19. Provide Optional Behavior with Keyword Arguments
    CLOSED: [2019-06-26 Wed 17:01]
    - State "DONE"       from "IN-PROGRESS" [2019-06-26 Wed 17:01]
    :LOGBOOK:
    CLOCK: [2019-06-26 Wed 16:53]--[2019-06-26 Wed 17:01] =>  0:08
    CLOCK: [2019-06-25 Tue 12:35]--[2019-06-25 Tue 12:41] =>  0:06
    CLOCK: [2019-06-25 Tue 11:37]--[2019-06-25 Tue 11:42] =>  0:05
    :END:
  
    All positional arguments to Python functions can also be passed by keyword.
 
    #+begin_src python :session :results output :exports both
      def remainder(number, divisor):
          return number % divisor

      print(remainder(20, 7) == 6)           # Using Position
      print(remainder(20, divisor=7) == 6)
      print(remainder(number=20, divisor=7) == 6)
      print(remainder(divisor=7, number=20) == 6)

      print(remainder(number=20, 7) == 6) # ERROR: Positional arguments must be specified before keywords

      print(remainder(20, number=7) == 6) # ERROR: Each arg can only be specified once number = 20, number = 7
    #+end_src

    #+RESULTS:
    : File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-9RVJJt/python-tdMtDL", line 9
    :     print(remainder(number=20, 7) == 6) # ERROR: Positional arguments must be specified before keywords
    :                               ^
    : SyntaxError: positional argument follows keyword argument
    : 
    : 

    *3 Benefits*

    1. Makes function calls clearer to new readers.  =remainder(20, 7)= vs =remainder(number=20, divisor=7)=
    2. Default values can be specified in the function definition. =def flow_rate(weight_diff, time_diff, period=1)=
    3. Provides a powerful way to extend a function's parameters while remaining backwards compatable with existing callers.
       - *But, DO ALWAYS provide optional arguments using the keyword names, not as positional arguments.*
      
    *Takeaways*
   
    - Function arguments can be specified by position or by keyword.
    - Keywords make it clear what the purpose of each argument is when it would be confusing with only positional arguments.
    - Keyword arguments with default values make it easy to add new behaviors to a function, especially when the function has exisitng callers.
    - Optional keyword arguments should always be passed by keyword instead of by position.
   

*** DONE 20. Use None and Docstrings to Specify Dynamic Default Arguments
    CLOSED: [2019-06-27 Thu 16:32]
    - State "DONE"       from "IN-PROGRESS" [2019-06-27 Thu 16:32]
    :LOGBOOK:
    CLOCK: [2019-06-27 Thu 15:55]--[2019-06-27 Thu 16:32] =>  0:37
    CLOCK: [2019-06-27 Thu 15:53]--[2019-06-27 Thu 15:53] =>  0:00
    :END:

    Default values that are dynamic.

    #+begin_src python :session :results output :exports both
      from datetime import datetime
      from time import sleep

      def log(message, when=datetime.now()):
          print('%s: %s' % (when, message))

      log('Hi there!')
      sleep(0.1)
      log('Hi again!')
    #+end_src

    #+RESULTS:
    : 2019-06-27 16:02:38.727596: Hi there!
    : 2019-06-27 16:02:38.727596: Hi again!
    : 
    : 

    But =datetime.now()= is evaluated when the function is defined, not when it is called.
   
    #+begin_src python :session :results output :exports both
      from datetime import datetime

      def log(message, when=None):
          """Log a message with a timestamp.

          Args:
              message: Message to print.
              when: datetime of when the message occurred.
                  Defaults to the present time.
          """

          when = datetime.now() if when is None else when
          print('%s: %s' % (when, message))

      log('Hi there!')
      log('Hi again!')
    #+end_src

    #+RESULTS:
    : 2019-06-27 16:06:48.103252: Hi there!
    : 2019-06-27 16:06:48.103289: Hi again!
    : 
    : 

    Now they are different.

    Using =None= for default argument values is important when the arguments are mutable.
   
     #+begin_src python :session :results output :exports both
       import json

       def decode(data, default={}):             # default is set to {} when the function is defined
           try:
               return json.loads(data)
           except ValueError:
               return default                    # returns the same mutable dict everytime


       def decode_better(data, default=None):
           """Load JSON data from a string.

           Args:
               data: JSON data to decode.
               default: Value to return if decoding fails.
                   Defaults to an empty dictionary.
           """

           if default is None:
               default = {}
           try:
               return json.loads(data)
           except ValueError:
               return default


       bad = decode('bad data')
       bad['bad_key'] = 5
       bad_too = decode('also bad')
       bad_too['another_bad_key'] = 1

       print('Mutable Dictionary as Default!')
       print('Bad: ', bad)
       print('Bad Too: ', bad_too)

       bad_better = decode_better('bad data')
       bad_better['bad_key'] = 5
       bad_too_better = decode_better('also bad')
       bad_too_better['another_bad_key'] = 1

       print('\nNone as Default')
       print('Bad Better: ', bad_better)
       print('Bad Too Better: ', bad_too_better)
    #+end_src

    #+RESULTS:
    : Mutable Dictionary as Default!
    : Bad:  {'bad_key': 5, 'another_bad_key': 1}
    : Bad Too:  {'bad_key': 5, 'another_bad_key': 1}
    : 
    : None as Default
    : Bad Better:  {'bad_key': 5}
    : Bad Too Better:  {'another_bad_key': 1}
    : 
    : 

    The values produced by =decode()= are the *same* because they are both the same instance of the =default= dictionary because it is defined during the module load. 
   
    The values produced by =decode_better()= are different because the default is defined at *runtime* when the function is called. 
  
    *Takeaways*
   
    - Default arguments are only evaluated once: during the function definition at module load time. This can cause add behaviors for dynamic values. (=[]= or ={}=)
    - Use =None= as the default value for keyword args that have a dynamic value. *Document the actual default behavior in the function's docstring.
   

*** DONE 21. Enforce Clarity with Keyword-Only Arguments
    CLOSED: [2019-06-28 Fri 14:40]
    - State "DONE"       from "IN-PROGRESS" [2019-06-28 Fri 14:40]
    :LOGBOOK:
    CLOCK: [2019-06-28 Fri 14:16]--[2019-06-28 Fri 14:40] =>  0:24
    :END:

    Example: Safe dividing

    #+begin_src python :session :results output :exports both
      def safe_division(number, divisor, ignore_overflow, ignore_zero_division):
          try:
              return number / divisor
          except OverflowError:
              if ignore_overflow:
                  return 0
              raise
          except ZeroDivisionError:
              if ignore_zero_division:
                  return float('inf')
              raise


      result = safe_division(1, 10**500, True, False)
      print(result)
      result = safe_division(1, 0, False, True)
      print(result)
    #+end_src

    #+RESULTS:
    : 0.0
    : inf
    : 
    : 

    The function works as expected, but is prone to errors because it is left up to the caller to remember the positions of the ignore parameters. 
    The caller could get very different results as a result of passing the incorrect arguments.
   
    A slightly better way of doing this is providing default values.

    #+begin_src python :session :results output :exports both
      def safe_division_b(number, divisor, ignore_overflow=False, ignore_zero_division=False):
          try:
              return number / divisor
          except OverflowError:
              if ignore_overflow:
                  return 0
              raise
          except ZeroDivisionError:
              if ignore_zero_division:
                  return float('inf')
              raise


      result = safe_division_b(1, 10**500, ignore_overflow=True)
      print(result)
      result = safe_division_b(1, 0, ignore_zero_division=True)
      print(result)
    #+end_src

    #+RESULTS:
    : 0.0
    : inf
    : 
    : 

    The issue here is, since these are optional, there's nothing forcing the callers to use keyword args for clarity.

    You can still call it by using positional args =result = safe_division(1, 0, False, True)=

    Demand clarity by requiring callers to be clear about their intentions.
    
    #+begin_src python :session :results output :exports both
      def safe_division_c(number, divisor, *, ignore_overflow=False, ignore_zero_division=False):
          try:
              return number / divisor
          except OverflowError:
              if ignore_overflow:
                  return 0
              raise
          except ZeroDivisionError:
              if ignore_zero_division:
                  return float('inf')
              raise


      result = safe_division_c(1, 10**500, ignore_overflow=True)
      print(result)
      result = safe_division_c(1, 0, ignore_zero_division=True)
      print(result)
      result = safe_division_c(1, 0, False, True)              # Error!
    #+end_src

    #+RESULTS:
    : /var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-VKajQJ/python-Op0jHw in <module>
    :      16 result = safe_division_c(1, 0, ignore_zero_division=True)
    :      17 print(result)
    : ---> 18 result = safe_division_c(1, 0, False, True)              # Error!
    : 
    : TypeError: safe_division_c() takes 2 positional arguments but 4 were given
    : 
    : 

    
    What does =*args= and =*kwargs= do?

    #+begin_src python :session :results output :exports both
      def meaningless(*args, **kwargs):
          for arg in args:
              print('Positional Arg: ', arg)

          for kwarg in kwargs:
              print('Keyword Arg: ', kwarg, '=', kwargs[kwarg])


      meaningless(1, 2, 'hello', world=True, name='Wallice')
    #+end_src

    #+RESULTS:
    : Positional Arg:  1
    : Positional Arg:  2
    : Positional Arg:  hello
    : Keyword Arg:  world = True
    : Keyword Arg:  name = Wallice
    : 
    : 

    *Takeaways*

    - Keyword args make the intention of a call more clear.
    - Use keyword-only args to force callers to supply keyword arguments for potentially confusing functions, especially Boolean flags.
    - Python 3 Supports explicit syntax for keyword-only arguments for functions.
    - Python 2 can emulate keyword-only arguments by using =**kwargs= and manually raising =TypeError= exceptions.


** Classes and Inheritance

*** DONE 22. Prefer Helper Classes Over Bookkeeping with Dictionaries and Tuples
    CLOSED: [2019-07-01 Mon 16:44]
    - State "DONE"       from "IN-PROGRESS" [2019-07-01 Mon 16:44]
    :LOGBOOK:
    CLOCK: [2019-07-01 Mon 16:09]--[2019-07-01 Mon 16:44] =>  0:35
    :END:
    
    Don't go too far with builtin data structures:

    #+begin_src python :session
      class SimpleGradebook(object):
          def __init__(self):
              self._grades = {}

          def add_student(self, name):
              self._grades[name] = []

          def report_grade(self, name, score):
              self._grades[name].append(score)

          def average_grade(self, name):
              grades = self._grades[name]
              return sum(grades) / len(grades)

      # Add some weight and subjects, it gets pretty complex

      class WeightedGradebook(object):
          def __init__(self):
              self._grades = {}

          def add_student(self, name):
              self._grades[name] = []

          def report_grade(self, name, subject, score, weight):
              by_subject = self._grades[name]
              grade_list = by_subject.setdefault(subject, [])
              grade_list.append((score, weight))

          def average_grade(self, name):
              by_subject = self._grades[name]
              score_sum, score_count = 0, 0
              for subject, scores in by_subject.values():
                  subject_avg, total_weight = 0, 0
                  for score, weight in scores:
                      # ...
                      pass
              return score_sum / score_count


      book = WeightedGradebook()
      book.add_student('Isaac Newton')
      book.report_grade('Isaac Newton', 'Math', 80, 0.10)
    #+end_src

    A lot could go wrong with this implementation, let's refactor to classes.
    
    #+begin_src python :session :results output :exports both
      class Grade(object):
          def __init__(self, score, weight):
              self.score = score
              self.weight = weight


      class Subject(object):
          def __init__(self):
              self._grades = []

          def report_grade(self, score, weight):
              self._grades.append(Grade(score, weight))

          def average_grade(self):
              total, total_weight = 0, 0
              for grade in self._grades:
                  total += grade.score * grade.weight
                  total_weight += grade.weight
              return total / total_weight

      class Student(object):
          def __init__(self):
              self._subjects = {}

          def subject(self, name):
              if name not in self._subjects:
                  self._subjects[name] = Subject()
              return self._subjects[name]

          def average_grade(self):
              total, count = 0, 0
              for subject in self._subjects.values():
                  total += subject.average_grade()
                  count += 1
              return total / count

      class Gradebook(object):
          def __init__(self):
              self._students = {}

          def student(self, name):
              if name not in self._students:
                  self._students[name] = Student()
              return self._students[name]

      book = Gradebook()
      albert = book.student('Albert Einstein')
      math = albert.subject('Math')
      math.report_grade(80, 0.10)

      print(albert.average_grade())
    #+end_src

    #+RESULTS:
    : 80.0
    : 
    : 

    *Takeaways*

    - Avoid nested dictionaries or long tuples.
    - Use =namedtuple= for lightweight, immutable data containers before you need the flexibility of a full class.
    - Move your bookkeeping code to use multiple helper classes when your internal state dictionaries get complicated.

      
*** DONE 23. Accept Functions for Simple Interfaces Instead of Classes
    CLOSED: [2019-07-02 Tue 11:32]
    - State "DONE"       from "IN-PROGRESS" [2019-07-02 Tue 11:32]
    :LOGBOOK:
    CLOCK: [2019-07-02 Tue 11:05]--[2019-07-02 Tue 11:32] =>  0:27
    :END:

    Use first-class functions to extend code. (stateless)

    #+begin_src python :session :results output :exports both
      from collections import defaultdict

      def log_missing():
          print('Key added')
          return 0

      current = {'green': 12, 'blue': 3}
      increments = [
          ('red', 5),
          ('blue', 17),
          ('orange', 9)
      ]
      result = defaultdict(log_missing, current)
      print('Before: ', dict(result))
      for key, amount in increments:
          result[key] += amount
      print('After: ', dict(result))
    #+end_src   

    #+RESULTS:
    : Before:  {'green': 12, 'blue': 3}
    : Key added
    : Key added
    : After:  {'green': 12, 'blue': 20, 'red': 5, 'orange': 9}
    : 
    : 


    If your function needs some state, use a _closure_.
    
    #+begin_src python :session :results output :exports both
      from collections import defaultdict

      def increment_with_report(current, increments):

          added_count = 0

          def missing():
              nonlocal added_count
              added_count += 1
              return 0

          result = defaultdict(missing, current)
          for key, amount in increments:
              result[key] += amount

          return result, added_count

      current = {'green': 12, 'blue': 3}
      increments = [
          ('red', 5),
          ('blue', 17),
          ('orange', 9)
      ]
      result, count = increment_with_report(current, increments)
      print(count == 2)
    #+end_src   

    #+RESULTS:
    : True
    : 
    : 

    But using a closure is harder to read than the stateless function. Let's use a small class that encapsulates the state.
    
    #+begin_src python :session :results output :exports both
      from collections import defaultdict

      class CountMissing(object):
          def __init__(self):
              self.added = 0

          def missing(self):
              self.added += 1
              return 0

      current = {'green': 12, 'blue': 3}
      increments = [
          ('red', 5),
          ('blue', 17),
          ('orange', 9)
      ]

      counter = CountMissing()
      result = defaultdict(counter.missing, current)
      for key, amount in increments:
          result[key] += amount

      print(counter.added == 2)
    #+end_src   

    #+RESULTS:
    : True
    : 
    : 


    This is clearer than the closure function, but it's not really obvious what to do with the class. Let's modify for better clarity.
    
    #+begin_src python :session :results output :exports both
      from collections import defaultdict

      class BetterCountMissing(object):
          def __init__(self):
              self.added = 0

          def __call__(self):
              self.added += 1
              return 0

      current = {'green': 12, 'blue': 3}
      increments = [
          ('red', 5),
          ('blue', 17),
          ('orange', 9)
      ]

      counter = BetterCountMissing()
      result = defaultdict(counter, current)  # Will invoke __call__() on the object passed in
      for key, amount in increments:
          result[key] += amount

      print(counter.added == 2)
    #+end_src   

    #+RESULTS:
    : True
    : 
    : 


    Much clearer than passing the method reference in the =CountMissing= class.

    *Takeaways*

    - Use functions instead of classes for interfaces between components in Python.
    - References to functions and methods in Python are first class (they can be used in expressions like other types).
    - =__call__= allows classes to be called like plain Python functions.
    - When you need a function to maintain state, consider defining a class that provides the =__call__= method instead of defining a stateful closure.


*** DONE 24. Use =@classmethod= Polymorphism to Construct Objects Generically
    CLOSED: [2019-07-09 Tue 14:47]
    - State "DONE"       from "IN-PROGRESS" [2019-07-09 Tue 14:47]
    :LOGBOOK:
    CLOCK: [2019-07-03 Wed 10:22]--[2019-07-03 Wed 10:53] =>  0:01
    :END:

    Create a MapReduce implementation with a common class to represent the input data.
    
    #+begin_src python :session :results output :exports both
      import threading
      import os


      # Abstract
      class InputData(object):
          def read(self):
              raise NotImplementedError

      # Concrete: Must implement read()
      class PathInputData(InputData):
          def __init__(self, path):
              super().__init__()
              self.path = path

          def read(self):
              return open(self.path).read()

      # Abstract
      class Worker(object):
          def __init__(self, input_data):
              self.input_data = input_data
              self.result = None

          def map(self):
              raise NotImplementedError

          def reduce(self):
              raise NotImplementedError

      # Concrete: Must implement map() and reduce()
      class LineCountWorker(Worker):
          def map(self):
              data = self.input_data.read()
              self.result = data.count('\n')

          def reduce(self, other):
              self.result += other.result


      # But, what's responsible for building these and orchestrating the MapReduce?

      def generate_inputs(data_dir):
          for name in os.listdir(data_dir):
              yield PathInputData(os.path.join(data_dir, name))  # Not generic, relies on PathInputData

      def create_workers(input_list):
          workers = []
          for input_data in input_list:
              workers.append(LineCountWorker(input_data)) # Not generic, relies on LineCountWorker
          return workers

      def execute(workers):
          threads = [Thread(target=w.map) for w in workers]
          for thread in threads: thread.start()
          for thread in threads: thread.join()

          first, rest = workers[0], workers[1:]
          for worker in rest:
              first.reduce(worker)
          return first.result

      # But, this is not generic, ie it can only work with PathInputData and LineCountWorker
      def mapreduce(data_dir):
          inputs = generate_inputs(data_dir)
          workers = create_workers(inputs)
          return execute(workers)

      from tempfile input TemporaryDirectory

      def write_test_fields(tmpdir):
          pass

      with TemporaryDirectory() as tmpdir:
          write_test_files(tmpdir)
          result = mapreduce(tmpdir)
    #+end_src   

    We know that this would work OK for =PathInputData= and =LineCountWorker=, but if we wanted to support another subclass of =InputData= or =Worker=, we'd have to write new functions (=mapreduce=, =create_workers=, =generate_inputs=) to support them. 
    
    How would we support constructing objects generically? We don't have constructor polymorphism in Python.

    Enter =@classmethod= polymorphism.
    
    #+begin_src python :session :results output :exports both
      class GenericInputData(object):
          def read(self):
              raise NotImplementedError

          @classmethod
          def generate_inputs(cls, config):
              raise NotImplementedError

      class PathInputData(GenericInputData):
          def __init__(self, path):
              super().__init__()
              self.path = path

          def read(self):
              return open(self.path).read()

          @classmethod
          def generate_inputs(cls, config):
              data_dir = config['data_dir']
              for name in os.listdir(data_dir):
                  yield cls(os.path.join(data_dir, name))

      class GenericWorker(object):
          def __init__(self, input_data):
              self.input_data = input_data
              self.result = None

          def map(self):
              raise NotImplementedError

          def reduce(self, other):
              raise NotImplementedError

          @classmethod
          def create_workers(cls, input_class, config):
              workers = []
              for input_data in input_class.generate_inputs(config): # class method polymorphism
                  workers.append(cls(input_data))
              return workers

      # Concrete: Must implement map() and reduce()
      class LineCountWorker(GenericWorker):
          def map(self):
              data = self.input_data.read()
              self.result = data.count('\n')

          def reduce(self, other):
              self.result += other.result

      def mapreduce(worker_class, input_class, config):
          workers = worker_class.create_workers(input_class, config)
          return execute(workers)

      from tempfile input TemporaryDirectory

      def write_test_fields(tmpdir):
          pass

      with TemporaryDirectory() as tmpdir:
          write_test_files(tmpdir)
          config = {'data_dir': tempdir}
          result = mapreduce(LineCountWorker, PahtInputData, config)
    #+end_src   
    
    Less code and way more flexible.

    *Takeaways*
    
    - Python only supports a single constructor per class (=__init__=).
    - Use =@classmethod= to define alternative constructors for your classes.
    - use =class= method polymorphism to provide generic ways to build and connect concrete subclasses.


*** DONE 25. Initialize Parent Classes with =super=
    CLOSED: [2019-07-10 Wed 11:17]
    - State "DONE"       from "IN-PROGRESS" [2019-07-10 Wed 11:17]
    :LOGBOOK:
    CLOCK: [2019-07-10 Wed 10:39]--[2019-07-10 Wed 11:17] =>  0:38
    :END:
    
    The old way of initializing a parent class

    #+begin_src python :session :results output :exports both
      class Base(object):
          def __init__(self, value):
              self.value = value

      class Child(Base):
          def __init__(self):
              Base.__init__(self, 5)


      print(Child().value)
    #+end_src   

    #+RESULTS:
    : 5

    This works ok for simple heirarchies, but breaks down in other cases.

    *Problem 1: =__init__= call order isn't specified across all subclasses.*
    
    #+begin_src python :session :results output :exports both
      class Base(object):
          def __init__(self, value):
              self.value = value

      class TimesTwo(object):
          def __init__(self):
              self.value *= 2

      class PlusFive(object):
          def __init__(self):
              self.value += 5

      class OneWay(Base, TimesTwo, PlusFive):
          def __init__(self, value):
              Base.__init__(self, value)
              TimesTwo.__init__(self)
              PlusFive.__init__(self)
      
      class AnotherWay(Base, PlusFive, TimesTwo):
          def __init__(self, value):
              Base.__init__(self, value)
              TimesTwo.__init__(self)
              PlusFive.__init__(self)

      class LastWay(Base, TimesTwo, PlusFive):
          def __init__(self, value):
              Base.__init__(self, value)
              PlusFive.__init__(self)
              TimesTwo.__init__(self) # <--- depends on the ordering of the __init__ calls.

      print(OneWay(5).value)
      print(AnotherWay(5).value)
      print(LastWay(5).value)
    #+end_src   

    #+RESULTS:
    : 15
    : 15
    : 20

    Both =OneWay= and =AnotherWay= produce the same value even though the ordering of inheritance is different.
    
    *Problem 2: Diamond inheritance causes the base of a base to be called multiple times.*
    
    #+begin_src python :session :results output :exports both
      class Base(object):
          def __init__(self, value):
              self.value = value

      class TimesFive(Base):
          def __init__(self, value):
              Base.__init__(self, value)
              self.value *= 5

      class PlusTwo(Base):
          def __init__(self, value):
              Base.__init__(self, value)
              self.value += 2

      class ThisWay(TimesFive, PlusTwo):
          def __init__(self, value):
              TimesFive.__init__(self, value)
              PlusTwo.__init__(self, value)  # <- resets Base.value = 5

      print('Should be (5 * 5) + 2 = 27, but it is: ', ThisWay(5).value)
    #+end_src

    #+RESULTS:
    : Should be (5 * 5) + 2 = 27, but it is:  7

    Let's use =super()= with diamond inheritance, since it will use method resolution order (MRO) to deterimine which classes are initialized in which order. Base classes are only initialized _once_.
    
    #+begin_src python :session :results output :exports both
      from pprint import pprint

      class Base(object):
          def __init__(self, value):
              self.value = value

      class TimesFiveCorrect(Base):
          def __init__(self, value):
              super(__class__, self).__init__(value) # Explicit
              self.value *= 5

      class PlusTwoCorrect(Base):
          def __init__(self, value):
              super().__init__(value)  # Implicit
              self.value += 2

      class GoodWay(TimesFiveCorrect, PlusTwoCorrect):
          def __init__(self, value):
              super(GoodWay, self).__init__(value)

      print('method resolution order (MRO)')
      pprint(GoodWay.mro())
      print('classes are initialized bottom up. Base (5), PlusTwoCorrect (5 + 2), TimesFiveCorrect (5 * (5 + 2))')
      print('Should be 5 * (5 + 2) = 35, which it is: ', GoodWay(5).value)
    #+end_src

    #+RESULTS:
    : method resolution order (MRO)
    : [<class '__main__.GoodWay'>,
    :  <class '__main__.TimesFiveCorrect'>,
    :  <class '__main__.PlusTwoCorrect'>,
    :  <class '__main__.Base'>,
    :  <class 'object'>]
    : classes are initialized bottom up. Base (5), PlusTwoCorrect (5 + 2), TimesFiveCorrect (5 * (5 + 2))
    : Should be 5 * (5 + 2) = 35, which it is:  35


    *Takeaways*
    - Python's standard method resolution order solves the problems of superclass initialization order and diamond inheritance.
    - *Always* use the =super= built-in function to initialize parent classes.


*** DONE 26. Use Multiple Inheritance Only for Mix-in Utility Classes
    CLOSED: [2019-07-11 Thu 15:51]
    - State "DONE"       from "IN-PROGRESS" [2019-07-11 Thu 15:51]
    :LOGBOOK:
    CLOCK: [2019-07-11 Thu 15:16]--[2019-07-11 Thu 15:51] =>  0:35
    :END:

    *Write a _mix-in_ instead of a full-blown class*
    
    > A mix-in is a small class that only defines a set of additional methods that a class should provide.
    
    #+begin_src python :session :results output :exports both
      from pprint import pprint
      import json

      class ToDictMixin(object):
          def to_dict(self):
              return self._traverse_dict(self.__dict__)

          def _traverse_dict(self, instance_dict):
              output = {}
              for key, value in instance_dict.items():
                  output[key] = self._traverse(key, value)
              return output

          def _traverse(self, key, value):
              if isinstance(value, ToDictMixin):
                  return value.to_dict()
              elif isinstance(value, dict):
                  return self._traverse_dict(value)
              elif isinstance(value, list):
                  return [self._traverse(key, i) for i in value]
              elif hasattr(value, '__dict__'):
                  return self._traverse_dict(value.__dict__)
              else:
                  return value

      class BinaryTree(ToDictMixin):
          def __init__(self, value, left=None, right=None):
              self.value = value
              self.left = left
              self.right = right


      tree = BinaryTree(10,
                        left=BinaryTree(7, right=BinaryTree(9)),
                        right=BinaryTree(13, left=BinaryTree(11)))

      pprint(tree.to_dict())

      print('What about subclasses?')


      class BinaryTreeWithParent(BinaryTree):
          def __init__(self, value, left=None, right=None, parent=None):
              super().__init__(value, left=left, right=right)
              self.parent = parent

          def _traverse(self, key, value):
              if (isinstance(value, BinaryTreeWithParent) and key == 'parent'):
                  return value.value # Prevent Infinite Cycles
              else:
                  return super()._traverse(key, value)



      root = BinaryTreeWithParent(10)
      root.left = BinaryTreeWithParent(7, parent=root)
      root.left.right = BinaryTreeWithParent(9, parent=root.left)

      pprint(root.to_dict())

      class JsonMixin(object):
          @classmethod
          def from_json(cls, data):
              kwargs = json.loads(data)
              return cls(**kwargs)

          def to_json(self):
              return json.dumps(self.to_dict())  # Whoa, using a method from another mixin?

      class DatacenterRack(ToDictMixin, JsonMixin):
          def __init__(self, switch=None, machines=None):
              self.switch = Switch(**switch)
              self.machines = [Machine(**kwargs) for kwargs in machines]

      class Switch(ToDictMixin, JsonMixin):
          def __init__(self, ports=None, speed=None):
              self.ports = ports
              self.speed = speed


      class Machine(ToDictMixin, JsonMixin):
          def __init__(self, cores=None, ram=None, disk=None):
              self.cores = cores
              self.ram = ram
              self.disk = disk


      serialized = """{
      "switch": {"ports": 5, "speed": 1e9},
      "machines": [
      {"cores": 8, "ram": 32e9, "disk": 5e12},
      {"cores": 4, "ram": 16e9, "disk": 1e12},
      {"cores": 2, "ram": 4e9, "disk": 500e12}
      ]
      }
      """

      deserialized = DatacenterRack.from_json(serialized)
      roundtrip = deserialized.to_json()

      pprint(json.loads(serialized))

      assert json.loads(serialized) == json.loads(roundtrip)
    #+end_src   

    #+RESULTS:
    #+begin_example
    {'left': {'left': None,
              'right': {'left': None, 'right': None, 'value': 9},
              'value': 7},
     'right': {'left': {'left': None, 'right': None, 'value': 11},
               'right': None,
               'value': 13},
     'value': 10}
    What about subclasses?
    {'left': {'left': None,
              'parent': 10,
              'right': {'left': None, 'parent': 7, 'right': None, 'value': 9},
              'value': 7},
     'parent': None,
     'right': None,
     'value': 10}
    {'machines': [{'cores': 8, 'disk': 5000000000000.0, 'ram': 32000000000.0},
                  {'cores': 4, 'disk': 1000000000000.0, 'ram': 16000000000.0},
                  {'cores': 2, 'disk': 500000000000000.0, 'ram': 4000000000.0}],
     'switch': {'ports': 5, 'speed': 1000000000.0}}
    #+end_example

    
    *Takeaways*
    
    - Avoid using multiple inheritance if mix-in classes can achieve the same outcome.
    - Use pluggable behaviors at the instance level to proveid per-class customization when mix-in classes may require it.
    - Compose mix-ins to create complex functionality from simple behaviors.


*** DONE 27. Prefer Public Attributes Over Private Ones
    CLOSED: [2019-07-12 Fri 15:42]
    - State "DONE"       from "IN-PROGRESS" [2019-07-12 Fri 15:42]
    :LOGBOOK:
    CLOCK: [2019-07-12 Fri 15:00]--[2019-07-12 Fri 15:42] =>  0:42
    :END:
    
    There are only two types of attribute visibility for a class's attributes: /public/ and /private/.

    #+begin_src python :session :results output :exports both
      class MyObject(object):
          def __init__(self):
              self.public_field = 5
              self.__private_field = 10

          def get_private_field(self):
              return self.__private_field

      assert MyObject().public_field == 5
      assert MyObject().get_private_field() == 10

      # MyObject().__private_field 
      # AttributeError: 'MyObject' object has no attribute '__private_field'
    #+end_src

    #+RESULTS:
   
    Class methods have access to private fields because they are declared in the class scope.
 
    #+begin_src python :session :results output :exports both
      class MyOtherObject(object):
          def __init__(self):
              self.__private_field = 71

          @classmethod
          def get_private_field_of_instance(cls, instance):
              return instance.__private_field

      assert MyOtherObject.get_private_field_of_instance(MyOtherObject()) == 71
    #+end_src

    #+RESULTS:

    Subclasses CANNOT access its parent's private fields.

    #+begin_src python :session :results output :exports both
      class MyParentObject(object):
          def __init__(self):
              self.__private_field = 71


      class MyChildObject(MyParentObject):
          def get_private_field(self):
              return self.__private_field

      # assert MyChildObject().get_private_field() == 71
      # AttributeError: 'MyChildObject' object has no attribute '_MyChildObject__private_field'

      print('but now we know the REAL implementation of the private field')

      obj = MyChildObject()
      print(obj._MyParentObject__private_field)
      print(obj.__dict__)
      obj._MyParentObject__private_field = 42
      print('oh man, I just changed a private field to', obj._MyParentObject__private_field)
    #+end_src

    #+RESULTS:
    : but now we know the REAL implementation of the private field
    : 71
    : {'_MyParentObject__private_field': 71}
    : oh man, I just changed a private field to 42

    Private field disaster.

    #+begin_src python :session :results output :exports both
      class MyClass(object):
          def __init__(self, value):
              self.__value = value

          def get_value(self):
              return str(self.__value)

      MyClass(5).get_value() == '5'

      print('What about subclassing?')

      class MyIntegerSubclass(MyClass):
          def get_value(self):
              return int(self._MyClass__value)

      assert MyIntegerSubclass(5).get_value() == 5
    #+end_src

    #+RESULTS:
    : What about subclassing?


    Looking good so far, but what if the hierarchy changes?
    
    #+begin_src python :session :results output :exports both
      class MyBaseClass(object):
          def __init__(self, value):
              self.__value = value

      class MyClass(MyBaseClass):
          def get_value(self):
              return str(self.__value)

      MyClass(5).get_value() == '5'

      print('What about subclassing?')

      class MyIntegerSubclass(MyClass):
          def get_value(self):
              return int(self._MyClass__value)

      assert MyIntegerSubclass(5).get_value() == 5
    #+end_src

    #+RESULTS:
    : Traceback (most recent call last):
    :   File "<stdin>", line 1, in <module>
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-5sNdnI/python-P6ex5W", line 10, in <module>
    :     MyClass(5).get_value() == '5'
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-5sNdnI/python-P6ex5W", line 8, in get_value
    :     return str(self.__value)
    : AttributeError: 'MyClass' object has no attribute '_MyClass__value'


    Only consider using private attributes when you worried about naming conflicts.

    #+begin_src python :session :results output :exports both
      class ApiClass(object):
          def __init__(self):
              self.__value = 5

          def get(self):
              return self.__value

      class Child(ApiClass):
          def __init__(self):
              super().__init__()
              self._value = 'hello'

      c = Child()
      print(c.get(), 'and', c._value, 'are different')
    #+end_src

    #+RESULTS:
    : 5 and hello are different

    *Takeaways*
    - Private attributes aren't rigorously enforced by the Python compiler.
    - Plan from the beginning to allow subclasses to do more with your internal APIs and attributes instead of locking then out by default.
    - Use documentation of protected fields to guide subclasses instead of trying to force access control with private attributes.
    - Only consider private attributes if worried about naming conflicts. (not a very strong argument)

      
*** DONE 28. Inherit from =collections.abc= for Custom Container Types
    CLOSED: [2019-07-15 Mon 14:26]
    - State "DONE"       from "IN-PROGRESS" [2019-07-15 Mon 14:26]
    :LOGBOOK:
    CLOCK: [2019-07-15 Mon 13:52]--[2019-07-15 Mon 14:26] =>  0:34
    :END:

    Inheriting from =list= because the Custom Container happens to be a =list=.

    #+begin_src python :session :results output :exports both
      class FrequencyList(list):
          def __init__(self, members):
              super().__init__(members)

          def frequency(self):
              counts = {}
              for item in self:
                  counts.setdefault(item, 0)
                  counts[item] += 1
              return counts

      freq_list = FrequencyList(['a', 'b', 'a', 'c', 'b', 'a', 'd'])
      print('Length is', len(freq_list))
      freq_list.pop()
      print('After pop:', repr(freq_list))
      print('Frequency:', freq_list.frequency())
    #+end_src

    #+RESULTS:
    : Length is 7
    : After pop: ['a', 'b', 'a', 'c', 'b', 'a']
    : Frequency: {'a': 3, 'b': 2, 'c': 1}

    For objects that you'd like to /feel/ like a =list=, allowing indexing, but isn't a =list= subclass.

    For example, you'd like to work with this =BinaryNode= the same way you'd work with a =list= or a =tuple=.

    #+begin_src python :session :results output :exports both
      class BinaryNode(object):
          def __init__(self, value, left=None, right=None):
              self.value = value
              self.left = left
              self.right = right


      class IndexableNode(BinaryNode):
          def _search(self, count, index):
              return (BinaryNode(5), 10)  # DFS really though

          def __getitem__(self, index):
              found, _ = self._search(0, index)
              if not found:
                  raise IndexError('Index out of range')
              return found.value


      tree = IndexableNode(
          10,
          left=IndexableNode(
              5,
              left=IndexableNode(2),
              right=IndexableNode(6, right=IndexableNode(7))),
          right=IndexableNode(15, left=IndexableNode(11)))

      print('LRR = ', tree.left.right.right.value)
      print('Index 0 =', tree[0])
      len(tree) # unsupported, we'd have to implement __len__
    #+end_src

    #+RESULTS:
    : LRR =  7
    : Index 0 = 5
    : Traceback (most recent call last):
    :   File "<stdin>", line 1, in <module>
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-5sNdnI/python-z1Pr5V", line 29, in <module>
    :     len(tree)
    : TypeError: object of type 'IndexableNode' has no len()

    But we'd really want to have =len=, =count=, =index=, and everything that makes it easy to work with sequences.

    #+begin_src python :session :results output :exports both
      class SequenceNode(IndexableNode):
          def __len__(self):
              _, count = self.search(0, None)
              return count


      tree = SequenceNode(
          # ...
      )
    #+end_src

    Enter =collections.abc=

    #+begin_src python :session :results output :exports both
        from collections.abc import Sequence

        class BadType(Sequence):
            pass

        x = BadType()
    #+end_src

    #+RESULTS:
    : Traceback (most recent call last):
    :   File "<stdin>", line 1, in <module>
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-5sNdnI/python-PjJoRI", line 6, in <module>
    :     x = BadType()
    : TypeError: Can't instantiate abstract class BadType with abstract methods __getitem__, __len__

    ^ Here it tells us what we need to support a =Sequence= derived class.


    #+begin_src python :session :results output :exports both
      class BetterNode(SequenceNode, Sequence):
          pass

      tree = BetterNode(
          # ...
      )
    #+end_src

    *Takeaways*
    
    - Inherit directly from Python's container types for simple use cases.
    - Beware of the large numbers of methods required to implement customer container types correctly.
    - Have you custom container types inherit from the interfaces in =collections.abc= to ensure that your classes match required interfaces and behaviors.

** Metaclasses and Attributes

   /Metaclasses/ let you intercept Python's =class= statement and provide special behavior each time a class is defined.

*** DONE 29. Use Plain Attributes Instead of Get and Set Methods
    CLOSED: [2019-07-17 Wed 16:01]
    - State "DONE"       from "IN-PROGRESS" [2019-07-17 Wed 16:01]
    :LOGBOOK:
    CLOCK: [2019-07-17 Wed 15:22]--[2019-07-17 Wed 16:01] =>  0:39
    :END:
    
    Bad Java type porting:

    #+begin_src python :session :results output :exports both
      class OldResistor(object):
          def __init__(self, ohms):
              self._ohms = ohms

          def get_ohms(self):
              return self._ohms

          def set_ohms(self, ohms):
              self._ohms = ohms


      r0 = OldResistor(50e3)
      print('Before: %5r' % r0.get_ohms())
      r0.set_ohms(10e3)
      print('After: %5r' % r0.get_ohms())

      # Not Pythonic
      r0.set_ohms(r0.get_ohms() + 5e3)
    #+end_src

    #+RESULTS:
    : Before: 50000.0
    : After: 10000.0


    You don't need to implement setters/getters

    #+begin_src python :session :results output :exports both
       class Resistor(object):
           def __init__(self, ohms):
               self.ohms = ohms
               self.voltage = 0
               self.current = 0

       r1 = Resistor(50e3)
       print('Before: %5r' % r1.ohms)
       r1.ohms += 10e3 # Way better
       print('After: %5r' % r1.ohms)
    #+end_src

    #+RESULTS:
    : Before: 50000.0
    : After: 60000.0

    Support special behavior with =@property= and =setter= when needed.
    
    #+begin_src python :session :results output :exports both
       class Resistor(object):
           def __init__(self, ohms):
               self.ohms = ohms
               self.voltage = 0
               self.current = 0

       class VoltageResistance(Resistor):
           def __init__(self, ohms):
               super().__init__(ohms)
               self._voltage = 0

           @property
           def voltage(self):
               return self._voltage

           @voltage.setter
           def voltage(self, voltage):
               self._voltage = voltage
               self.current = self._voltage / self.ohms

       r2 = VoltageResistance(1e3)
       print('Before: %5r amps' % r2.current)
       r2.voltage = 10  # voltage setter invoked
       print('After: %5r amps' % r2.current)
    #+end_src

    #+RESULTS:
    : Before:     0 amps
    : After:  0.01 amps
    : 10

    A =setter= also allows for type checking and validation on values.
    
    #+begin_src python :session :results output :exports both
       class Resistor(object):
           def __init__(self, ohms):
               self.ohms = ohms
               self.voltage = 0
               self.current = 0

       class BoundedResistor(Resistor):
           def __init__(self, ohms):
               super().__init__(ohms)

           @property
           def ohms(self):
               return self._ohms

           @ohms.setter
           def ohms(self, ohms):
               if ohms <= 0:
                   raise ValueError('%f ohms must be > 0' % ohms)
               self._ohms = ohms


       r3 = BoundedResistor(1e3)
       r3.ohms = 0 # Raises exception

       BoundedResistor(-5) # Raises exception
    #+end_src

    #+RESULTS:
    : Traceback (most recent call last):
    :   File "<stdin>", line 1, in <module>
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-owNSMT/python-vZyXeQ", line 23, in <module>
    :     r3.ohms = 0
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-owNSMT/python-vZyXeQ", line 18, in ohms
    :     raise ValueError('%f ohms must be > 0' % ohms)
    : ValueError: 0.000000 ohms must be > 0

    =BoundedResistor().__init__= assigns =self.ohms = -5=, which invokes =@ohms.setter=. 

    You could use =@property= for making attributes from parent classes immutable.
    
    #+begin_src python :session :results output :exports both
       class Resistor(object):
           def __init__(self, ohms):
               self.ohms = ohms
               self.voltage = 0
               self.current = 0

       class FixedResistance(Resistor):
           def __init__(self, ohms):
               super().__init__(ohms)

           @property
           def ohms(self):
               return self._ohms

           @ohms.setter
           def ohms(self, ohms):
               if hasattr(self, '_ohms'):
                   raise AttributeError("Can't set attribute")
               self._ohms = ohms


       r4 = FixedResistance(1e3)
       r4.ohms = 2e3 # Raises exception
    #+end_src

    #+RESULTS:
    : Traceback (most recent call last):
    :   File "<stdin>", line 1, in <module>
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-owNSMT/python-q6u0NV", line 23, in <module>
    :     r4.ohms = 2e3 # Raises exception
    :   File "/var/folders/bz/tc86r39x3yb0dm00h93xbbn40000gn/T/babel-owNSMT/python-q6u0NV", line 18, in ohms
    :     raise AttributeError("Can't set attribute")
    : AttributeError: Can't set attribute

    Don't implement /suprising/ behavior in =@property=.

    #+begin_src python :session :results output :exports both
      class Resistor(object):
          def __init__(self, ohms):
              self.ohms = ohms
              self.voltage = 0
              self.current = 0

      class MysteriousResistor(Resistor):
          def __init__(self, ohms):
              super().__init__(ohms)

          @property
          def ohms(self):
              self.voltage = self._ohms * self.current
              return self._ohms

    
      r5 = MysteriousResistor(10)
      r5.current = 0.01
      print('Before: %5r' % r5.voltage)
      r5.ohms  # Getting ohms updates another property in the class BAD
      print('After: %5r' % r5.voltage)
    #+end_src

    #+RESULTS:
    : Before:     0
    : After:   0.1

    *Takeaways*

    - Avoid set and get methods, use simple public attributes.
    - Use =@property= to define special behavior when attributes are accessed on your objects, if necessary.
    - Follow the rule of least surprise and avoid weird side effects in your =@property= methods.
    - =@property= methods should be fast. Slow or complex work should be done in normal methods.
   

*** DONE 30. Consider =@property= Instead of Refactoring Attributes
    CLOSED: [2019-07-19 Fri 15:53]
    - State "DONE"       from "IN-PROGRESS" [2019-07-19 Fri 15:53]
    :LOGBOOK:
    CLOCK: [2019-07-19 Fri 15:32]--[2019-07-19 Fri 15:53] =>  0:21
    :END:

    =@property= makes it easy for simple access of an instance's attributes to act smarter.

    Example without the use of =@property=.
    
    #+begin_src python :session :results output :exports both
      from datetime import datetime, timedelta

      class Bucket(object):
          def __init__(self, period):
              self.period_delta = timedelta(seconds=period)
              self.reset_time = datetime.now()
              self.quota = 0

          def __repr__(self):
              return 'Bucket(quota=%d)' % self.quota

      def fill(bucket, amount):
          now = datetime.now()
          if now - bucket.reset_time > bucket.period_delta:
              bucket.quota = 0
              bucket.reset_time = now
          bucket.quota += amount

      def deduct(bucket, amount):
          now = datetime.now()
          if now - bucket.reset_time > bucket.period_delta:
              return False
          if bucket.quota - amount < 0:
              return False
          bucket.quota -= amount
          return True

      bucket = Bucket(60)
      fill(bucket, 100)
      print(bucket)

      if deduct(bucket, 99):
          print('Had 99 quota')
      else:
          print('Not enough for 99 quota')
      print(bucket)

      if deduct(bucket, 3):
          print('Had 3 quota')
      else:
          print('Not enough for 3 quota')
      print(bucket)
    #+end_src

    #+RESULTS:
    : Bucket(quota=100)
    : Had 99 quota
    : Bucket(quota=1)
    : Not enough for 3 quota
    : Bucket(quota=1)

    We always have to compute the quota ourselves. Not a very useful implementation.
    
    Let's redesign.
    
    #+begin_src python :session :results output :exports both
      from datetime import datetime, timedelta

      class Bucket(object):
          def __init__(self, period):
              self.period_delta = timedelta(seconds=period)
              self.reset_time = datetime.now()
              self.max_quota = 0
              self.quota_consumed = 0

          def __repr__(self):
              return 'Bucket(max_quota=%d, quota_consumed=%d)' % (self.max_quota, self.quota_consumed)

          @property
          def quota(self):
              return self.max_quota - self.quota_consumed

          @quota.setter
          def quota(self, amount):
              delta = self.max_quota - amount
              if amount == 0:
                  self.quota_consumed = 0
                  self.max_quota = 0
              elif delta < 0:
                  assert self.quota_consumed == 0
                  self.max_quota = amount
              else:
                  assert self.max_quota >= self.quota_consumed
                  self.quota_consumed += delta

      def fill(bucket, amount):
          now = datetime.now()
          if now - bucket.reset_time > bucket.period_delta:
              bucket.quota = 0
              bucket.reset_time = now
          bucket.quota += amount

      def deduct(bucket, amount):
          now = datetime.now()
          if now - bucket.reset_time > bucket.period_delta:
              return False
          if bucket.quota - amount < 0:
              return False
          bucket.quota -= amount
          return True

      bucket = Bucket(60)
      print('Initial', bucket)
      fill(bucket, 100)
      print('Filled', bucket)

      if deduct(bucket, 99):
          print('Had 99 quota')
      else:
          print('Not enough for 99 quota')

      print('Now', bucket)

      if deduct(bucket, 3):
          print('Had 3 quota')
      else:
          print('Not enough for 3 quota')

      print('Still', bucket)
    #+end_src

    #+RESULTS:
    : Initial Bucket(max_quota=0, quota_consumed=0)
    : Filled Bucket(max_quota=100, quota_consumed=0)
    : Had 99 quota
    : Now Bucket(max_quota=100, quota_consumed=99)
    : Not enough for 3 quota
    : Still Bucket(max_quota=100, quota_consumed=99)

    That's a better, and non-destructive way to incremently improve a container class.
    
    *Takeaways*

    - Use =@property= to give existing instance attributes new functionality.
    - Make incremental progress toward better data models by using =@property=.
    - Consider refactoring a class and all call sites when you find yourself using =@property= too heavily.


*** TODO 31. Use Descriptors for Reusable =@property= Methods

*** TODO 32. Use =__getattr__=, =__getattribute__=, and =__setattr__= for Lazy Attributes

*** TODO 33. Validate Subclasses with Metaclasses

*** TODO 34. Register Class Existence with Metaclasses

*** TODO 35. Annotate Class Attributes with Metaclasses

** Concurrency and Parallelism

** Built-in Modules

** Collaboration

** Production
  
** Time

 #+BEGIN: clocktable :scope file :maxlevel 3
 #+CAPTION: Clock summary at [2019-07-19 Fri 15:55]
 | Headline                                       | Time    |      |      |
 |------------------------------------------------+---------+------+------|
 | *Total time*                                   | *10:30* |      |      |
 |------------------------------------------------+---------+------+------|
 | \_  Pythonic Thinking                          |         | 1:27 |      |
 | \_    8. Avoid More Than Two Expressions in... |         |      | 0:07 |
 | \_    9. Consider Generator Expressions for... |         |      | 0:22 |
 | \_    10. Prefer =enumerate= over =range=      |         |      | 0:14 |
 | \_    11. Use =zip= to Process Iterators in... |         |      | 0:14 |
 | \_    12. Avoid =else= Blocks After =for=...   |         |      | 0:10 |
 | \_    13. Take Advantage of Each Block in...   |         |      | 0:20 |
 | \_  Functions                                  |         | 4:01 |      |
 | \_    14. Prefer Exceptions to Returning...    |         |      | 0:18 |
 | \_    15. Know How Closures Interact with...   |         |      | 0:24 |
 | \_    16. Consider Generators Instead of...    |         |      | 0:26 |
 | \_    17. Be Defensive When Iterating Over...  |         |      | 1:05 |
 | \_    18. Reduce Visual Noise with Variable... |         |      | 0:28 |
 | \_    19. Provide Optional Behavior with...    |         |      | 0:19 |
 | \_    20. Use None and Docstrings to...        |         |      | 0:37 |
 | \_    21. Enforce Clarity with Keyword-Only... |         |      | 0:24 |
 | \_  Classes and Inheritance                    |         | 4:02 |      |
 | \_    22. Prefer Helper Classes Over...        |         |      | 0:35 |
 | \_    23. Accept Functions for Simple...       |         |      | 0:27 |
 | \_    24. Use =@classmethod= Polymorphism...   |         |      | 0:31 |
 | \_    25. Initialize Parent Classes with...    |         |      | 0:38 |
 | \_    26. Use Multiple Inheritance Only for... |         |      | 0:35 |
 | \_    27. Prefer Public Attributes Over...     |         |      | 0:42 |
 | \_    28. Inherit from =collections.abc=...    |         |      | 0:34 |
 | \_  Metaclasses and Attributes                 |         | 1:00 |      |
 | \_    29. Use Plain Attributes Instead of...   |         |      | 0:39 |
 | \_    30. Consider =@property= Instead of...   |         |      | 0:21 |
 #+END:
 
